{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cefbbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import simpledbf\n",
    "from simpledbf import Dbf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d570b7",
   "metadata": {},
   "source": [
    "# Capacity\n",
    "\n",
    "### Year Infos\n",
    "le but c'est de créer une lecture automatisé de chaque année, donc on crée un dictionnaire avec le chemin et les noms de\n",
    "colomnes d'interêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb50419",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-58a6652a74b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0myear_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data_Treatment/Data/Capacity/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'eia860'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#il y a un documents qui je ne sais pas d'où il vient, mais qui ne nous intêret pas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "year_infos = {}\n",
    "for folder in os.listdir('Data_Treatment/Data/Capacity/'):\n",
    "    if folder[:6] != 'eia860': #il y a un documents qui je ne sais pas d'où il vient, mais qui ne nous intêret pas\n",
    "        continue\n",
    "    year = int(folder[-4:])\n",
    "    for file in os.listdir(f'Data_Treatment/Data/Capacity/{folder}'):\n",
    "        \n",
    "        if year < 2004: #objectif = 2001 ->2003. On doit les traîter separemment puisqu'ils sont un fichier dbf\n",
    "            if file[:3].upper() == 'GEN' and file[-3:]=='dbf': #c'est le fichier desire, mais il est encore en format dbf\n",
    "                    old_path = 'Data_Treatment/Data/Capacity/'+folder+'/'+file\n",
    "                    dbf = Dbf5(old_path)\n",
    "                    new_path = 'Data_Treatment/Data/Capacity/'+folder+'/'+file[:-3]+'csv'\n",
    "                    dbf.to_csv(new_path)\n",
    "                    path = new_path\n",
    "                    energy_source = 'ENSOURCE1'\n",
    "                    capacity = 'NAMEPLATE'\n",
    "                    year_infos[year] = [path,energy_source,capacity]\n",
    "\n",
    "        \n",
    "        elif year<= 2012: #il y a eu un changement dans comment les fichiers s'appelent\n",
    "            if file[:3].upper() == 'GEN':\n",
    "                if file[-3:] not in ['xls','lsx']:\n",
    "                    continue # je vais traiter les fichiers .dbf (2001-2003) après\n",
    "                path = 'Data_Treatment/Data/Capacity/'+folder+'/'+file\n",
    "                energy_source = 'ENERGY_SOURCE_1'\n",
    "                capacity = 'NAMEPLATE'\n",
    "                if year == 2012:\n",
    "                    energy_source = 'Energy Source 1'\n",
    "                    capacity = 'Nameplate Capacity (MW)'\n",
    "                \n",
    "                year_infos[year] = [path,energy_source,capacity]\n",
    "        else:\n",
    "            if file[:4] == '3_1_':\n",
    "                path = 'Data_Treatment/Data/Capacity/'+folder+'/'+file\n",
    "                energy_source = 'Energy Source 1'\n",
    "                capacity = 'Nameplate Capacity (MW)'\n",
    "                year_infos[year] = [path,energy_source,capacity]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be4a24",
   "metadata": {},
   "source": [
    "## Codes et Technologies\n",
    "le but c'est de bien separer les types de technologie à partir des codes existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48ca5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_2020, energy_source_2020, capacity_2020= year_infos[2020][0],year_infos[2020][1], year_infos[2020][2]\n",
    "#df_2020 = pd.read_excel(path_2020,header = 1)\n",
    "\n",
    "#energies = ['Onshore Wind Turbine','Natural Gas Steam Turbine', 'Conventional Steam Coal', 'Solar Photovoltaic']\n",
    "#technologies = {}\n",
    "#codes = []\n",
    "\n",
    "#for technology in df_2020['Technology'].unique():\n",
    "#    if technology in energies: \n",
    "#        energy_source = df_2020['Energy Source 1'].where(df_2020['Technology']==technology).dropna().unique()\n",
    "#        print(technology,energy_source)\n",
    "#        technologies[technology] = energy_source\n",
    "#        codes.append(energy_source)\n",
    "\n",
    "#print(technologies)\n",
    "#print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851a4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = ['WND','NG','BIT','LIG','SUB','RC','WC','SUN']\n",
    "codes_technologies = {'WND': 'Onshore Wind Turbine', 'NG': 'Natural Gas Steam Turbine', 'SUN': 'Solar Photovoltaic',\n",
    "                     'BIT': 'Conventional Steam Coal', 'LIG': 'Conventional Steam Coal', 'SUB': 'Conventional Steam Coal',\n",
    "                     'RC': 'Conventional Steam Coal', 'WC': 'Conventional Steam Coal'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6092ae6",
   "metadata": {},
   "source": [
    "## Delete_other_headers\n",
    "on en utilise pour qu'on fasse le traitement des archives 2001->2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9537703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_other_headers(df): #dans les dfs plus agés (2001-03), il y avait plus d'un entete (header), et les numéros parfois n'étaient pas tous en format float\n",
    "    df_interest = pd.DataFrame()\n",
    "    df_interest['ENSOURCE1'],df_interest['NAMEPLATE'] = df['ENSOURCE1'],df['NAMEPLATE']\n",
    "    #on doit effacer les lignes qui sont entetes, c-a-d: on trouvera celles où le valuer dans 'NAMEPLATE' \n",
    "    #est aussi 'NAMEPLATE'\n",
    "    index = 0\n",
    "    indexes=[]\n",
    "    for line in df['NAMEPLATE']:\n",
    "        if line == \"NAMEPLATE\":\n",
    "            indexes.append(index)\n",
    "        index+=1\n",
    "    df_interest = df_interest.drop(indexes,axis=0)\n",
    "    df_interest['NAMEPLATE'] = df_interest['NAMEPLATE'].apply(lambda x: float(x))\n",
    "    #On a pu le faire directment puisque toutes les lignes étaient en format '1231.2', s'il avait quelqu'une differente,\n",
    "    #il aurait jeté une exception\n",
    "    return(df_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b76cd",
   "metadata": {},
   "source": [
    "# Merge Production & Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaaafbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_infos = {'solar':['Data_Treatment/treated_data/Production/solar_treated.csv','Solar Photovoltaic'],\n",
    "                      'wind':['Data_Treatment/treated_data/Production/wind_treated.csv','Onshore Wind Turbine'],\n",
    "                      'coal':['Data_Treatment/treated_data/Production/coal_treated.csv','Conventional Steam Coal'],\n",
    "                     'gas':['Data_Treatment/treated_data/Production/gas_treated.csv','Natural Gas Steam Turbine']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5e4cd",
   "metadata": {},
   "source": [
    "# Panel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c688729",
   "metadata": {},
   "source": [
    "Dictionnaire pour agilizer la découverte des noms des colomns d'interêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83e96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year_columns = {}\n",
    "\n",
    "#for year in year_infos:\n",
    "#    path = year_infos[year][0]\n",
    "\n",
    "#    if year <=2003:\n",
    "        #df_year_raw = pd.read_csv(path,header = 0)\n",
    "\n",
    "#    elif year<=2010:\n",
    "        #df_year_raw = pd.read_excel(path,header = 0)\n",
    "    \n",
    "#    else: \n",
    "        #df_year_raw = pd.read_excel(path,header = 1)\n",
    "    #year_columns[year] = df_year_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc3cfb",
   "metadata": {},
   "source": [
    "avec la recherche, on peut faire le filtrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed7837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in year_infos:\n",
    "    if year>2003 and year<=2006:\n",
    "        state = 'STATE'\n",
    "        plant = 'PLNTCODE'\n",
    "        month = 'INSVMONTH'\n",
    "    elif year>2006 and year <=2008:\n",
    "        state = 'STATE'\n",
    "        plant = 'PLNTCODE'\n",
    "        month = 'OPERATING_MONTH'\n",
    "    elif year>2008 and year<=2011 :\n",
    "        state = 'STATE'\n",
    "        plant = 'PLANT_CODE'\n",
    "        month = 'OPERATING_MONTH'\n",
    "    elif year>2011:\n",
    "        state = 'State'\n",
    "        plant = 'Plant Code'\n",
    "        month = 'Operating Month'\n",
    "    year_infos[year].append(state)\n",
    "    year_infos[year].append(plant)\n",
    "    year_infos[year].append(month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2dd68-9361-47d5-8545-563f3dab11b3",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b957c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sum_df(df,column):\n",
    "    df_tool = df.groupby(['Year']).sum()\n",
    "    df_result = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df_tool)): # ici on utilise le range normal, 0 -> 2021-1973, puisque les ans presents dans df_renewable_month sont les indexes\n",
    "        year = df_tool.iloc[i].name\n",
    "        col = df_tool.iloc[i][column]\n",
    "        new_row = pd.DataFrame({'Year': year, column: col}, index = [i])\n",
    "        df_result=df_result.append(new_row, ignore_index = False)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def gen_count_df(df,column):\n",
    "    df_tool = df.groupby(['Year']).count()\n",
    "    df_result = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df_tool)): # ici on utilise le range normal, 0 -> 2021-1973, puisque les ans presents dans df_renewable_month sont les indexes\n",
    "        year = df_tool.iloc[i].name\n",
    "        col = df_tool.iloc[i][column]\n",
    "        new_row = pd.DataFrame({'Year': year, column: col}, index = [i])\n",
    "        df_result=df_result.append(new_row, ignore_index = False)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def gen_max_df(df,column):\n",
    "    df_tool = df.groupby(['Year']).max()\n",
    "    df_result = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df_tool)): # ici on utilise le range normal, 0 -> 2021-1973, puisque les ans presents dans df_renewable_month sont les indexes\n",
    "        year = df_tool.iloc[i].name\n",
    "        col = df_tool.iloc[i][column]\n",
    "        new_row = pd.DataFrame({'Year': year, column: col}, index = [i])\n",
    "        df_result=df_result.append(new_row, ignore_index = False)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def iterative_merge(list_dfs):\n",
    "    df = list_dfs[0]\n",
    "    for i in range(1,len(list_dfs)-1):\n",
    "        df_merged = pd.merge(df,list_dfs[i+1], on = 'Year')\n",
    "        df = df_merged\n",
    "        df_merged = pd.DataFrame()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b10175-6f1e-483a-84fc-a6e6c2f0cf23",
   "metadata": {},
   "source": [
    "# Technology Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bc21e8-1379-4087-92a3-081ea20ffc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_code = {'Coal':['ANT','BIT','LIG','SUB','SGC','WC'],\n",
    "                  'Petroleum Products': ['DFO','JF','KER','PC','PG','RFO','SG','WO'],\n",
    "                   'Natural Gas':['NG'],\n",
    "                   'Other Gases': ['BFG','OG'],\n",
    "                   'Nuclear':['NUC'],\n",
    "                   'Hidroeletric':['WAT'],\n",
    "                   'Wood and Wood-Delivered Fuels':['WDS','WDL','BLW'],\n",
    "                   'Other Biomass':['AB','MSW', 'OBG', 'OBL', 'OBS', 'LFG', 'SLW'],\n",
    "                   'Solar':['SUN'],\n",
    "                   'Wind':['WND'],\n",
    "                   'Geothermical':['GEO'],\n",
    "                   'Other':['PUR','WH','TDF','MWH']\n",
    "                  }\n",
    "\n",
    "code_to_technology = {}\n",
    "\n",
    "for technology in technology_code:\n",
    "    for code in technology_code[technology]:\n",
    "        code_to_technology[code]=technology\n",
    "        \n",
    "        \n",
    "def convert_to_technology(x):\n",
    "    try:\n",
    "        return(code_to_technology[x])\n",
    "    except:\n",
    "        return('Not in the Appendix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f4743-9353-4e4d-af5f-8fa22b6d3cdf",
   "metadata": {},
   "source": [
    "# Map USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c6440e-a826-4162-9bf3-a7382b00f8d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}\n",
    "    \n",
    "# invert the dictionary\n",
    "abbrev_to_us_state = dict(map(reversed, us_state_to_abbrev.items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
